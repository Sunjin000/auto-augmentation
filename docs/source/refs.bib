@misc{noauthor_image_nodate,
	title = {Image {Classification} {Explained}: {An} {Introduction}},
	shorttitle = {Image {Classification} {Explained}},
	url = {https://www.v7labs.com/blog/image-classification-guide, https://www.v7labs.com/blog/image-classification-guide},
	abstract = {What is image classification and how does it work? Check out this beginner's guide to image recognition and build your own image classifier using V7.},
	urldate = {2022-04-26},
	file = {Snapshot:C\:\\Users\\carte\\Zotero\\storage\\TINPUIZW\\image-classification-guide.html:text/html},
}

@misc{noauthor_mnist_nodate,
	title = {{MNIST} classification {\textbar} {TensorFlow} {Quantum}},
	url = {https://www.tensorflow.org/quantum/tutorials/mnist},
	language = {en},
	urldate = {2022-04-26},
	journal = {TensorFlow},
	file = {Snapshot:C\:\\Users\\carte\\Zotero\\storage\\H7PEMKC8\\mnist.html:text/html},
}

@misc{brownlee_overfitting_2016,
	title = {Overfitting and {Underfitting} {With} {Machine} {Learning} {Algorithms}},
	url = {https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/},
	abstract = {The cause of poor performance in machine learning is either overfitting or underfitting the data. In this post, you will discover the […]},
	language = {en-US},
	urldate = {2022-04-26},
	journal = {Machine Learning Mastery},
	author = {Brownlee, Jason},
	month = mar,
	year = {2016},
}

@misc{silaparasetty_how_2020,
	title = {How to {Handle} {Overfitting} and {Underfitting}},
	url = {https://medium.datadriveninvestor.com/how-to-handle-overfitting-and-underfitting-470a1f7389fe},
	abstract = {What is Overfitting?},
	language = {en},
	urldate = {2022-04-26},
	journal = {Medium},
	author = {Silaparasetty, Vinita},
	month = mar,
	year = {2020},
	file = {Snapshot:C\:\\Users\\carte\\Zotero\\storage\\57JXISKW\\how-to-handle-overfitting-and-underfitting-470a1f7389fe.html:text/html},
}

@article{roh_survey_2019,
	title = {A {Survey} on {Data} {Collection} for {Machine} {Learning}: a {Big} {Data} -- {AI} {Integration} {Perspective}},
	shorttitle = {A {Survey} on {Data} {Collection} for {Machine} {Learning}},
	url = {http://arxiv.org/abs/1811.03402},
	abstract = {Data collection is a major bottleneck in machine learning and an active research topic in multiple communities. There are largely two reasons data collection has recently become a critical issue. First, as machine learning is becoming more widely-used, we are seeing new applications that do not necessarily have enough labeled data. Second, unlike traditional machine learning, deep learning techniques automatically generate features, which saves feature engineering costs, but in return may require larger amounts of labeled data. Interestingly, recent research in data collection comes not only from the machine learning, natural language, and computer vision communities, but also from the data management community due to the importance of handling large amounts of data. In this survey, we perform a comprehensive study of data collection from a data management point of view. Data collection largely consists of data acquisition, data labeling, and improvement of existing data or models. We provide a research landscape of these operations, provide guidelines on which technique to use when, and identify interesting research challenges. The integration of machine learning and data management for data collection is part of a larger trend of Big data and Artificial Intelligence (AI) integration and opens many opportunities for new research.},
	urldate = {2022-04-26},
	journal = {arXiv:1811.03402 [cs, stat]},
	author = {Roh, Yuji and Heo, Geon and Whang, Steven Euijong},
	month = aug,
	year = {2019},
	note = {arXiv: 1811.03402},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 20 pages},
	file = {arXiv Fulltext PDF:C\:\\Users\\carte\\Zotero\\storage\\DHUXYFTU\\Roh et al. - 2019 - A Survey on Data Collection for Machine Learning .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\carte\\Zotero\\storage\\LQUXVET2\\1811.html:text/html},
}

@misc{noauthor_data_2021,
	title = {Data {Augmentation} {\textbar} {How} to use {Deep} {Learning} when you have {Limited} {Data}},
	url = {https://nanonets.com/blog/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2/},
	abstract = {This article is a comprehensive review of Data Augmentation techniques for Deep Learning, specific to images.},
	language = {en},
	urldate = {2022-04-26},
	journal = {AI \& Machine Learning Blog},
	month = may,
	year = {2021},
	file = {Snapshot:C\:\\Users\\carte\\Zotero\\storage\\7P2XIDB6\\data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2.html:text/html},
}

@article{cubuk_autoaugment_2019,
	title = {{AutoAugment}: {Learning} {Augmentation} {Policies} from {Data}},
	shorttitle = {{AutoAugment}},
	url = {http://arxiv.org/abs/1805.09501},
	abstract = {Data augmentation is an effective technique for improving the accuracy of modern image classifiers. However, current data augmentation implementations are manually designed. In this paper, we describe a simple procedure called AutoAugment to automatically search for improved data augmentation policies. In our implementation, we have designed a search space where a policy consists of many sub-policies, one of which is randomly chosen for each image in each mini-batch. A sub-policy consists of two operations, each operation being an image processing function such as translation, rotation, or shearing, and the probabilities and magnitudes with which the functions are applied. We use a search algorithm to find the best policy such that the neural network yields the highest validation accuracy on a target dataset. Our method achieves state-of-the-art accuracy on CIFAR-10, CIFAR-100, SVHN, and ImageNet (without additional data). On ImageNet, we attain a Top-1 accuracy of 83.5\% which is 0.4\% better than the previous record of 83.1\%. On CIFAR-10, we achieve an error rate of 1.5\%, which is 0.6\% better than the previous state-of-the-art. Augmentation policies we find are transferable between datasets. The policy learned on ImageNet transfers well to achieve significant improvements on other datasets, such as Oxford Flowers, Caltech-101, Oxford-IIT Pets, FGVC Aircraft, and Stanford Cars.},
	urldate = {2022-04-26},
	journal = {arXiv:1805.09501 [cs, stat]},
	author = {Cubuk, Ekin D. and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V.},
	month = apr,
	year = {2019},
	note = {arXiv: 1805.09501},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: CVPR 2019},
	file = {arXiv Fulltext PDF:C\:\\Users\\carte\\Zotero\\storage\\SP92PZZI\\Cubuk et al. - 2019 - AutoAugment Learning Augmentation Policies from D.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\carte\\Zotero\\storage\\65HPN9QJ\\1805.html:text/html},
}

@article{shorten_survey_2019,
	title = {A survey on {Image} {Data} {Augmentation} for {Deep} {Learning}},
	abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
	language = {en},
	author = {Shorten, Connor},
	year = {2019},
	pages = {48},
	file = {Shorten - 2019 - A survey on Image Data Augmentation for Deep Learn.pdf:C\:\\Users\\carte\\Zotero\\storage\\LWGHX2PI\\Shorten - 2019 - A survey on Image Data Augmentation for Deep Learn.pdf:application/pdf},
}

@article{zheng_deep_2022,
	title = {Deep {AutoAugment}},
	url = {http://arxiv.org/abs/2203.06172},
	abstract = {While recent automated data augmentation methods lead to state-of-the-art results, their design spaces and the derived data augmentation strategies still incorporate strong human priors. In this work, instead of fixing a set of hand-picked default augmentations alongside the searched data augmentations, we propose a fully automated approach for data augmentation search named Deep AutoAugment (DeepAA). DeepAA progressively builds a multi-layer data augmentation pipeline from scratch by stacking augmentation layers one at a time until reaching convergence. For each augmentation layer, the policy is optimized to maximize the cosine similarity between the gradients of the original and augmented data along the direction with low variance. Our experiments show that even without default augmentations, we can learn an augmentation policy that achieves strong performance with that of previous works. Extensive ablation studies show that the regularized gradient matching is an effective search method for data augmentation policies. Our code is available at: https://github.com/MSU-MLSys-Lab/DeepAA .},
	urldate = {2022-04-26},
	journal = {arXiv:2203.06172 [cs]},
	author = {Zheng, Yu and Zhang, Zhi and Yan, Shen and Zhang, Mi},
	month = mar,
	year = {2022},
	note = {arXiv: 2203.06172
version: 2},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	annote = {Comment: ICLR 2022 camera-ready. Code: https://github.com/MSU-MLSys-Lab/DeepAA},
	file = {arXiv Fulltext PDF:C\:\\Users\\carte\\Zotero\\storage\\P93EVGP9\\Zheng et al. - 2022 - Deep AutoAugment.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\carte\\Zotero\\storage\\5QXTRUP9\\2203.html:text/html},
}

@article{lim_fast_2019,
	title = {Fast {AutoAugment}},
	url = {http://arxiv.org/abs/1905.00397},
	abstract = {Data augmentation is an essential technique for improving generalization ability of deep learning models. Recently, AutoAugment has been proposed as an algorithm to automatically search for augmentation policies from a dataset and has significantly enhanced performances on many image recognition tasks. However, its search method requires thousands of GPU hours even for a relatively small dataset. In this paper, we propose an algorithm called Fast AutoAugment that finds effective augmentation policies via a more efficient search strategy based on density matching. In comparison to AutoAugment, the proposed algorithm speeds up the search time by orders of magnitude while achieves comparable performances on image recognition tasks with various models and datasets including CIFAR-10, CIFAR-100, SVHN, and ImageNet.},
	urldate = {2022-04-26},
	journal = {arXiv:1905.00397 [cs, stat]},
	author = {Lim, Sungbin and Kim, Ildoo and Kim, Taesup and Kim, Chiheon and Kim, Sungwoong},
	month = may,
	year = {2019},
	note = {arXiv: 1905.00397
version: 2},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: 8 pages, 2 figure},
	file = {arXiv Fulltext PDF:C\:\\Users\\carte\\Zotero\\storage\\GPKZSM7G\\Lim et al. - 2019 - Fast AutoAugment.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\carte\\Zotero\\storage\\3FMICMUX\\1905.html:text/html},
}

@article{lingchen_uniformaugment_2020,
	title = {{UniformAugment}: {A} {Search}-free {Probabilistic} {Data} {Augmentation} {Approach}},
	shorttitle = {{UniformAugment}},
	url = {http://arxiv.org/abs/2003.14348},
	abstract = {Augmenting training datasets has been shown to improve the learning effectiveness for several computer vision tasks. A good augmentation produces an augmented dataset that adds variability while retaining the statistical properties of the original dataset. Some techniques, such as AutoAugment and Fast AutoAugment, have introduced a search phase to find a set of suitable augmentation policies for a given model and dataset. This comes at the cost of great computational overhead, adding up to several thousand GPU hours. More recently RandAugment was proposed to substantially speedup the search phase by approximating the search space by a couple of hyperparameters, but still incurring non-negligible cost for tuning those. In this paper we show that, under the assumption that the augmentation space is approximately distribution invariant, a uniform sampling over the continuous space of augmentation transformations is sufficient to train highly effective models. Based on that result we propose UniformAugment, an automated data augmentation approach that completely avoids a search phase. In addition to discussing the theoretical underpinning supporting our approach, we also use the standard datasets, as well as established models for image classification, to show that UniformAugment's effectiveness is comparable to the aforementioned methods, while still being highly efficient by virtue of not requiring any search.},
	urldate = {2022-04-26},
	journal = {arXiv:2003.14348 [cs]},
	author = {LingChen, Tom Ching and Khonsari, Ava and Lashkari, Amirreza and Nazari, Mina Rafi and Sambee, Jaspreet Singh and Nascimento, Mario A.},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.14348
version: 1},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\carte\\Zotero\\storage\\5676I3TP\\LingChen et al. - 2020 - UniformAugment A Search-free Probabilistic Data A.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\carte\\Zotero\\storage\\474C3DQP\\2003.html:text/html},
}

@misc{kexugit_test_nodate,
	title = {Test {Run} - {The} {UCB1} {Algorithm} for {Multi}-{Armed} {Bandit} {Problems}},
	url = {https://docs.microsoft.com/en-us/archive/msdn-magazine/2019/august/test-run-the-ucb1-algorithm-for-multi-armed-bandit-problems},
	language = {en-us},
	urldate = {2022-04-26},
	author = {kexugit},
	file = {Snapshot:C\:\\Users\\carte\\Zotero\\storage\\P2IZN3GN\\test-run-the-ucb1-algorithm-for-multi-armed-bandit-problems.html:text/html},
}

@article{wang_learning_2017,
	title = {Learning to reinforcement learn},
	url = {http://arxiv.org/abs/1611.05763},
	abstract = {In recent years deep reinforcement learning (RL) systems have attained superhuman performance in a number of challenging task domains. However, a major limitation of such applications is their demand for massive amounts of training data. A critical present objective is thus to develop deep RL methods that can adapt rapidly to new tasks. In the present work we introduce a novel approach to this challenge, which we refer to as deep meta-reinforcement learning. Previous work has shown that recurrent networks can support meta-learning in a fully supervised context. We extend this approach to the RL setting. What emerges is a system that is trained using one RL algorithm, but whose recurrent dynamics implement a second, quite separate RL procedure. This second, learned RL algorithm can differ from the original one in arbitrary ways. Importantly, because it is learned, it is configured to exploit structure in the training domain. We unpack these points in a series of seven proof-of-concept experiments, each of which examines a key aspect of deep meta-RL. We consider prospects for extending and scaling up the approach, and also point out some potentially important implications for neuroscience.},
	urldate = {2022-04-26},
	journal = {arXiv:1611.05763 [cs, stat]},
	author = {Wang, Jane X. and Kurth-Nelson, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z. and Munos, Remi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matt},
	month = jan,
	year = {2017},
	note = {arXiv: 1611.05763},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: 17 pages, 7 figures, 1 table},
	file = {arXiv Fulltext PDF:C\:\\Users\\carte\\Zotero\\storage\\F7FMNXVG\\Wang et al. - 2017 - Learning to reinforcement learn.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\carte\\Zotero\\storage\\F29CRMA7\\1611.html:text/html},
}

@article{vanschoren_meta-learning_2018,
	title = {Meta-{Learning}: {A} {Survey}},
	shorttitle = {Meta-{Learning}},
	url = {http://arxiv.org/abs/1810.03548},
	abstract = {Meta-learning, or learning to learn, is the science of systematically observing how different machine learning approaches perform on a wide range of learning tasks, and then learning from this experience, or meta-data, to learn new tasks much faster than otherwise possible. Not only does this dramatically speed up and improve the design of machine learning pipelines or neural architectures, it also allows us to replace hand-engineered algorithms with novel approaches learned in a data-driven way. In this chapter, we provide an overview of the state of the art in this fascinating and continuously evolving field.},
	urldate = {2022-04-26},
	journal = {arXiv:1810.03548 [cs, stat]},
	author = {Vanschoren, Joaquin},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.03548},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\carte\\Zotero\\storage\\ZI58U7XT\\Vanschoren - 2018 - Meta-Learning A Survey.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\carte\\Zotero\\storage\\DF3DHJRT\\1810.html:text/html},
}

@misc{weng_meta_2019,
	title = {Meta {Reinforcement} {Learning}},
	url = {https://lilianweng.github.io/posts/2019-06-23-meta-rl/},
	abstract = {In my earlier post on meta-learning, the problem is mainly defined in the context of few-shot classification. Here I would like to explore more into cases when we try to “meta-learn” Reinforcement Learning (RL) tasks by developing an agent that can solve unseen tasks fast and efficiently.
To recap, a good meta-learning model is expected to generalize to new tasks or new environments that have never been encountered during training. The adaptation process, essentially a mini learning session, happens at test with limited exposure to the new configurations.},
	language = {en},
	urldate = {2022-04-26},
	author = {Weng, Lilian},
	month = jun,
	year = {2019},
	note = {Section: posts},
}

@article{ko_adaptive_nodate,
	title = {Adaptive {Scheduling} of {Data} {Augmentation} for {Deep} {Reinforcement} {Learning}},
	abstract = {We consider data augmentation technique to improve data efficiency and generalization performance of reinforcement learning (RL). Our empirical study on Open AI Procgen shows that the timing of augmentation is critical, and that to maximize test performance, an augmentation should be applied either during the entire RL training, or after the end of RL training. More specifically, if the regularization imposed by augmentation is helpful only in testing, then augmentation is best used after training than during training, because augmentation often disturbs the training process. Conversely, an augmentation that provides regularization that is useful in training should be used during the whole training period to fully utilize its benefit in terms of both generalization and data efficiency. Considering our findings, we propose a mechanism to fully exploit a set of augmentations, which automatically identifies the best augmentation (or no augmentation) in terms of RL training performance, and then utilizes all the augmentations by network distillation after training to maximize test performance. Our experiment empirically justifies the proposed method compared to other automatic augmentation mechanism.},
	language = {en},
	author = {Ko, Byungchan and Ok, Jungseul},
	pages = {11},
	file = {Ko and Ok - Adaptive Scheduling of Data Augmentation for Deep .pdf:C\:\\Users\\carte\\Zotero\\storage\\6IL87XSR\\Ko and Ok - Adaptive Scheduling of Data Augmentation for Deep .pdf:application/pdf},
}

@article{liu_automated_nodate,
	title = {Automated {Deep} {Learning}: {Principles} and {Practice}},
	language = {en},
	author = {Liu, Zhengying},
	pages = {241},
	file = {Liu - Automated Deep Learning Principles and Practice.pdf:C\:\\Users\\carte\\Zotero\\storage\\JS8Z3857\\Liu - Automated Deep Learning Principles and Practice.pdf:application/pdf},
}


@misc{pygad,
  title = {PyGad},
  howpublished = {\url{https://pygad.readthedocs.io/}},
  note = {Accessed: 2022-04-30}
}

@misc{Flask,
  title = {Flask framework},
  howpublished = {\url{https://flask.palletsprojects.com/en/2.1.x/
}},
  note = {Accessed: 2022-05-02}
}


@misc{React,
  title = {React framework},
  howpublished = {\url{https://reactjs.org/}},
  note = {Accessed: 2022-05-02}
}


@misc{PyPip,
  title = {Auto-Augmentation PyPi website},
  howpublished = {\url{https://pypi.org/project/auto-augmentation/0.1/}},
  note = {Accessed: 2022-05-02}
}


@misc{readthedocs,
  title = {Auto-Augmentation readthedocs documentation},
  howpublished = {\url{https://autoaug.readthedocs.io/en/latest/index.html#}},
  note = {Accessed: 2022-05-02}
}



@misc{metarl_survey,
  doi = {10.48550/ARXIV.1810.03548},
  
  url = {https://arxiv.org/abs/1810.03548},
  
  author = {Vanschoren, Joaquin},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Meta-Learning: A Survey},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

%for more information see https://en.wikibooks.org/wiki/LaTeX/Bibliography_Management
@article{autoaugment,
  author    = {Ekin Dogus Cubuk and
               Barret Zoph and
               Dandelion Man{\'{e}} and
               Vijay Vasudevan and
               Quoc V. Le},
  title     = {AutoAugment: Learning Augmentation Policies from Data},
  journal   = {CoRR},
  volume    = {abs/1805.09501},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.09501},
  eprinttype = {arXiv},
  eprint    = {1805.09501},
  timestamp = {Mon, 13 Aug 2018 16:48:44 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-09501.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{randomsearch,
  author  = {James Bergstra and Yoshua Bengio},
  title   = {Random Search for Hyper-Parameter Optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2012},
  volume  = {13},
  number  = {10},
  pages   = {281-305},
  url     = {http://jmlr.org/papers/v13/bergstra12a.html}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{neural_arch_search,
  author    = {Barret Zoph and
               Quoc V. Le},
  title     = {Neural Architecture Search with Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1611.01578},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.01578},
  eprinttype = {arXiv},
  eprint    = {1611.01578},
  timestamp = {Mon, 13 Aug 2018 16:46:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ZophL16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06347},
  eprinttype = {arXiv},
  eprint    = {1707.06347},
  timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{fast_autoaugment,
  author    = {Sungbin Lim and
               Ildoo Kim and
               Taesup Kim and
               Chiheon Kim and
               Sungwoong Kim},
  title     = {Fast AutoAugment},
  journal   = {CoRR},
  volume    = {abs/1905.00397},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.00397},
  eprinttype = {arXiv},
  eprint    = {1905.00397},
  timestamp = {Mon, 27 May 2019 13:15:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-00397.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{trivial_augment,
  doi = {10.48550/ARXIV.2103.10158},
  
  url = {https://arxiv.org/abs/2103.10158},
  
  author = {Müller, Samuel G. and Hutter, Frank},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {TrivialAugment: Tuning-free Yet State-of-the-Art Data Augmentation},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{sota_benchmark, title={Papers with code - imagenet benchmark (data augmentation)}, url={https://paperswithcode.com/sota/data-augmentation-on-imagenet}, journal={The latest in Machine Learning}} 

@misc{four_docs, title={The Four Kinds of Documentation and Why You Need to ...}, url={https://www.writethedocs.org/videos/eu/2017/the-four-kinds-of-documentation-and-why-you-need-to-understand-what-they-are-daniele-procida/}, journal={Internet}} 



@article{population_based_aug,
  author    = {Daniel Ho and
               Eric Liang and
               Ion Stoica and
               Pieter Abbeel and
               Xi Chen},
  title     = {Population Based Augmentation: Efficient Learning of Augmentation
               Policy Schedules},
  journal   = {CoRR},
  volume    = {abs/1905.05393},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.05393},
  eprinttype = {arXiv},
  eprint    = {1905.05393},
  timestamp = {Tue, 28 May 2019 12:48:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-05393.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{pytest, title={pytest}, url={https://docs.pytest.org/en/7.1.x/}} 

@misc{scikit, title={scikit}, url={https://scikit-learn.org/stable/}}

@article{gru,
  author    = {Junyoung Chung and
               {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
               KyungHyun Cho and
               Yoshua Bengio},
  title     = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence
               Modeling},
  journal   = {CoRR},
  volume    = {abs/1412.3555},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.3555},
  eprinttype = {arXiv},
  eprint    = {1412.3555},
  timestamp = {Mon, 13 Aug 2018 16:47:38 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ChungGCB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}