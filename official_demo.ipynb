{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoaug\n",
    "import autoaug.autoaugment_learners as aal\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, img_height=28, img_width=28, num_labels=10, img_channels=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(img_channels, 6, 5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(int((((img_height-4)/2-4)/2)*(((img_width-4)/2-4)/2)*16), 120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, num_labels)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.relu1(y)\n",
    "        y = self.pool1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool2(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu3(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.relu4(y)\n",
    "        y = self.fc3(y)\n",
    "        y = self.relu5(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "                        root='./autoaug/datasets/mnist/train',\n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=None\n",
    "                        )\n",
    "val_dataset = datasets.MNIST(\n",
    "                        root='./autoaug/datasets/mnist/test',\n",
    "                        train=False,\n",
    "                        download=True,\n",
    "                        transform=torchvision.transforms.ToTensor()\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the child network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_network_architecture = LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### specifying parameters for the auto-augment learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space_hyp = {\n",
    "        'exclude_method': ['Invert', 'Solarize']\n",
    "        }\n",
    "child_network_hyp = {\n",
    "        'learning_rate': 0.01,\n",
    "        'early_stop_num': 5,\n",
    "        'batch_size': 32,\n",
    "        'toy_size': 0.005\n",
    "        }\n",
    "\n",
    "\n",
    "learner = aal.RsLearner(\n",
    "                        **search_space_hyp,\n",
    "                        **child_network_hyp,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the auto-augment learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('Posterize', 0.8, 3), ('Rotate', 0.6, 4)),\n",
      " (('Rotate', 1.0, 9), ('Sharpness', 0.1, 1)),\n",
      " (('ShearY', 0.5, 4), ('Sharpness', 0.9, 3)),\n",
      " (('Posterize', 0.0, 6), ('Rotate', 0.0, 9)),\n",
      " (('ShearX', 0.3, 9), ('Brightness', 0.1, 7))]\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.1400)\n",
      "main.train_child_network best accuracy:  tensor(0.1400)\n",
      "main.train_child_network best accuracy:  tensor(0.1400)\n",
      "main.train_child_network best accuracy:  tensor(0.1400)\n",
      "main.train_child_network best accuracy:  tensor(0.1400)\n",
      "[(('Sharpness', 0.6, 9), ('Rotate', 0.4, 2)),\n",
      " (('AutoContrast', 0.3, None), ('ShearX', 0.7, 3)),\n",
      " (('Contrast', 0.3, 7), ('ShearX', 0.8, 8)),\n",
      " (('Equalize', 0.0, None), ('Sharpness', 0.8, 0)),\n",
      " (('AutoContrast', 0.0, None), ('Sharpness', 0.3, 3))]\n",
      "main.train_child_network best accuracy:  tensor(0.1200)\n",
      "main.train_child_network best accuracy:  tensor(0.1200)\n",
      "main.train_child_network best accuracy:  tensor(0.1200)\n",
      "main.train_child_network best accuracy:  tensor(0.1200)\n",
      "main.train_child_network best accuracy:  tensor(0.1200)\n",
      "[(('Color', 0.5, 4), ('Color', 0.3, 6)),\n",
      " (('Brightness', 0.4, 1), ('ShearX', 0.0, 4)),\n",
      " (('TranslateX', 0.9, 2), ('TranslateX', 1.0, 4)),\n",
      " (('Posterize', 0.9, 9), ('Equalize', 0.0, None)),\n",
      " (('TranslateY', 0.4, 7), ('Sharpness', 0.0, 0))]\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n",
      "[(('Rotate', 0.6, 0), ('Posterize', 0.8, 4)),\n",
      " (('Contrast', 0.4, 8), ('Color', 0.8, 9)),\n",
      " (('Contrast', 0.4, 3), ('Equalize', 0.8, None)),\n",
      " (('TranslateX', 0.5, 4), ('TranslateY', 0.8, 4)),\n",
      " (('TranslateX', 0.8, 2), ('AutoContrast', 0.0, None))]\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.1400)\n",
      "main.train_child_network best accuracy:  tensor(0.1400)\n",
      "main.train_child_network best accuracy:  tensor(0.1400)\n",
      "main.train_child_network best accuracy:  tensor(0.1400)\n",
      "main.train_child_network best accuracy:  tensor(0.1400)\n",
      "[(('Brightness', 1.0, 8), ('ShearX', 0.7, 6)),\n",
      " (('Rotate', 0.6, 8), ('TranslateY', 0.7, 3)),\n",
      " (('Rotate', 0.1, 0), ('Contrast', 0.2, 1)),\n",
      " (('AutoContrast', 0.7, None), ('Brightness', 0.0, 7)),\n",
      " (('Equalize', 0.5, None), ('TranslateY', 0.3, 2))]\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "[(('TranslateX', 0.4, 3), ('TranslateY', 0.2, 3)),\n",
      " (('Sharpness', 0.7, 1), ('TranslateX', 0.2, 7)),\n",
      " (('Brightness', 0.7, 1), ('Color', 0.6, 7)),\n",
      " (('TranslateX', 0.8, 2), ('Color', 0.3, 3)),\n",
      " (('Sharpness', 0.9, 7), ('ShearY', 0.4, 6))]\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n",
      "[(('TranslateY', 0.5, 6), ('Posterize', 0.3, 4)),\n",
      " (('Rotate', 0.5, 8), ('Brightness', 0.1, 3)),\n",
      " (('Posterize', 0.5, 2), ('Brightness', 0.8, 7)),\n",
      " (('Color', 0.1, 0), ('Sharpness', 0.7, 8)),\n",
      " (('Brightness', 0.8, 9), ('TranslateX', 0.7, 0))]\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "[(('Color', 0.7, 5), ('AutoContrast', 0.3, None)),\n",
      " (('TranslateX', 0.9, 6), ('Equalize', 0.2, None)),\n",
      " (('ShearY', 0.9, 5), ('Color', 0.4, 9)),\n",
      " (('ShearX', 0.8, 6), ('Contrast', 0.7, 7)),\n",
      " (('Equalize', 0.4, None), ('ShearY', 0.5, 1))]\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "main.train_child_network best accuracy:  tensor(0.0800)\n",
      "[(('Contrast', 0.8, 1), ('ShearX', 0.7, 5)),\n",
      " (('TranslateY', 1.0, 2), ('Equalize', 0.1, None)),\n",
      " (('AutoContrast', 0.8, None), ('TranslateX', 0.0, 5)),\n",
      " (('Sharpness', 0.7, 4), ('Color', 0.9, 9)),\n",
      " (('ShearX', 0.5, 7), ('Rotate', 0.6, 6))]\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n",
      "main.train_child_network best accuracy:  tensor(0.1000)\n"
     ]
    }
   ],
   "source": [
    "learner.learn(\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=val_dataset,\n",
    "        child_network_architecture=child_network_architecture,\n",
    "        iterations = 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([(('Posterize', 0.8, 3), ('Rotate', 0.6, 4)),\n",
      "   (('Rotate', 1.0, 9), ('Sharpness', 0.1, 1)),\n",
      "   (('ShearY', 0.5, 4), ('Sharpness', 0.9, 3)),\n",
      "   (('Posterize', 0.0, 6), ('Rotate', 0.0, 9)),\n",
      "   (('ShearX', 0.3, 9), ('Brightness', 0.1, 7))],\n",
      "  0.14000000059604645),\n",
      " ([(('Rotate', 0.6, 0), ('Posterize', 0.8, 4)),\n",
      "   (('Contrast', 0.4, 8), ('Color', 0.8, 9)),\n",
      "   (('Contrast', 0.4, 3), ('Equalize', 0.8, None)),\n",
      "   (('TranslateX', 0.5, 4), ('TranslateY', 0.8, 4)),\n",
      "   (('TranslateX', 0.8, 2), ('AutoContrast', 0.0, None))],\n",
      "  0.14000000059604645)]\n"
     ]
    }
   ],
   "source": [
    "# pretty print\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(learner.get_n_best_policies(2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ff322598041d883b259d9bb11f69934c6eb464e784fc0c772ba36565c383509"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
