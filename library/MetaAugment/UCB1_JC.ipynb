{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U_ZJ2LqDiu_v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data_utils\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy import save, load\n",
        "from tqdm import trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4ksS_duLFADW"
      },
      "outputs": [],
      "source": [
        "\"\"\"Define internal NN module that trains on the dataset\"\"\"\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self, img_height, img_width, num_labels, img_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(img_channels, 6, 5)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(int((((img_height-4)/2-4)/2)*(((img_width-4)/2-4)/2)*16), 120)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(84, num_labels)\n",
        "        self.relu5 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)\n",
        "        y = self.relu1(y)\n",
        "        y = self.pool1(y)\n",
        "        y = self.conv2(y)\n",
        "        y = self.relu2(y)\n",
        "        y = self.pool2(y)\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.relu3(y)\n",
        "        y = self.fc2(y)\n",
        "        y = self.relu4(y)\n",
        "        y = self.fc3(y)\n",
        "        y = self.relu5(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LckxnUXGfxjW"
      },
      "outputs": [],
      "source": [
        "\"\"\"Define internal NN module that trains on the dataset\"\"\"\n",
        "class EasyNet(nn.Module):\n",
        "    def __init__(self, img_height, img_width, num_labels, img_channels):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(img_height*img_width*img_channels, 2048)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(2048, num_labels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = x.view(x.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.relu1(y)\n",
        "        y = self.fc2(y)\n",
        "        y = self.relu2(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "enaD2xbw5hew"
      },
      "outputs": [],
      "source": [
        "\"\"\"Define internal NN module that trains on the dataset\"\"\"\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, img_height, img_width, num_labels, img_channels):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(img_height*img_width*img_channels, num_labels)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = x.view(x.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.relu1(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xujQtvVWBgMH"
      },
      "outputs": [],
      "source": [
        "\"\"\"Make toy dataset\"\"\"\n",
        "\n",
        "def create_toy(train_dataset, test_dataset, batch_size, n_samples):\n",
        "    \n",
        "    # shuffle and take first n_samples %age of training dataset\n",
        "    shuffle_order_train = np.random.RandomState(seed=100).permutation(len(train_dataset))\n",
        "    shuffled_train_dataset = torch.utils.data.Subset(train_dataset, shuffle_order_train)\n",
        "    indices_train = torch.arange(int(n_samples*len(train_dataset)))\n",
        "    reduced_train_dataset = data_utils.Subset(shuffled_train_dataset, indices_train)\n",
        "\n",
        "    # shuffle and take first n_samples %age of test dataset\n",
        "    shuffle_order_test = np.random.RandomState(seed=1000).permutation(len(test_dataset))\n",
        "    shuffled_test_dataset = torch.utils.data.Subset(test_dataset, shuffle_order_test)\n",
        "    indices_test = torch.arange(int(n_samples*len(test_dataset)))\n",
        "    reduced_test_dataset = data_utils.Subset(shuffled_test_dataset, indices_test)\n",
        "\n",
        "    # push into DataLoader\n",
        "    train_loader = torch.utils.data.DataLoader(reduced_train_dataset, batch_size=batch_size)\n",
        "    test_loader = torch.utils.data.DataLoader(reduced_test_dataset, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Iql-c88jGGWy"
      },
      "outputs": [],
      "source": [
        "\"\"\"Randomly generate 10 policies\"\"\"\n",
        "\"\"\"Each policy has 5 sub-policies\"\"\"\n",
        "\"\"\"For each sub-policy, pick 2 transformations, 2 probabilities and 2 magnitudes\"\"\"\n",
        "\n",
        "def generate_policies(num_policies, num_sub_policies):\n",
        "    \n",
        "    policies = np.zeros([num_policies,num_sub_policies,6])\n",
        "\n",
        "    # Policies array will be 10x5x6\n",
        "    for policy in range(num_policies):\n",
        "        for sub_policy in range(num_sub_policies):\n",
        "            # pick two sub_policy transformations (0=rotate, 1=shear, 2=scale)\n",
        "            policies[policy, sub_policy, 0] = np.random.randint(0,3)\n",
        "            policies[policy, sub_policy, 1] = np.random.randint(0,3)\n",
        "            while policies[policy, sub_policy, 0] == policies[policy, sub_policy, 1]:\n",
        "                policies[policy, sub_policy, 1] = np.random.randint(0,3)\n",
        "\n",
        "            # pick probabilities\n",
        "            policies[policy, sub_policy, 2] = np.random.randint(0,11) / 10\n",
        "            policies[policy, sub_policy, 3] = np.random.randint(0,11) / 10\n",
        "\n",
        "            # pick magnitudes\n",
        "            for transformation in range(2):\n",
        "                if policies[policy, sub_policy, transformation] <= 1:\n",
        "                    policies[policy, sub_policy, transformation + 4] = np.random.randint(-4,5)*5\n",
        "                elif policies[policy, sub_policy, transformation] == 2:\n",
        "                    policies[policy, sub_policy, transformation + 4] = np.random.randint(5,15)/10\n",
        "\n",
        "    return policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QE2VWI8o731X"
      },
      "outputs": [],
      "source": [
        "\"\"\"Pick policy and sub-policy\"\"\"\n",
        "\"\"\"Each row of data should have a different sub-policy but for now, this will do\"\"\"\n",
        "\n",
        "def sample_sub_policy(policies, policy, num_sub_policies):\n",
        "    sub_policy = np.random.randint(0,num_sub_policies)\n",
        "\n",
        "    degrees = 0\n",
        "    shear = 0\n",
        "    scale = 1\n",
        "\n",
        "    # check for rotations\n",
        "    if policies[policy, sub_policy][0] == 0:\n",
        "        if np.random.uniform() < policies[policy, sub_policy][2]:\n",
        "            degrees = policies[policy, sub_policy][4]\n",
        "    elif policies[policy, sub_policy][1] == 0:\n",
        "        if np.random.uniform() < policies[policy, sub_policy][3]:\n",
        "            degrees = policies[policy, sub_policy][5]\n",
        "\n",
        "    # check for shears\n",
        "    if policies[policy, sub_policy][0] == 1:\n",
        "        if np.random.uniform() < policies[policy, sub_policy][2]:\n",
        "            shear = policies[policy, sub_policy][4]\n",
        "    elif policies[policy, sub_policy][1] == 1:\n",
        "        if np.random.uniform() < policies[policy, sub_policy][3]:\n",
        "            shear = policies[policy, sub_policy][5]\n",
        "\n",
        "    # check for scales\n",
        "    if policies[policy, sub_policy][0] == 2:\n",
        "        if np.random.uniform() < policies[policy, sub_policy][2]:\n",
        "            scale = policies[policy, sub_policy][4]\n",
        "    elif policies[policy, sub_policy][1] == 2:\n",
        "        if np.random.uniform() < policies[policy, sub_policy][3]:\n",
        "            scale = policies[policy, sub_policy][5]\n",
        "\n",
        "    return degrees, shear, scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vu_4I4qkbx73"
      },
      "outputs": [],
      "source": [
        "\"\"\"Sample policy, open and apply above transformations\"\"\"\n",
        "def run_UCB1(policies, batch_size, learning_rate, ds, toy_size, max_epochs, early_stop_num, iterations, IsLeNet):\n",
        "\n",
        "    # get number of policies and sub-policies\n",
        "    num_policies = len(policies)\n",
        "    num_sub_policies = len(policies[0])\n",
        "\n",
        "    #Initialize vector weights, counts and regret\n",
        "    q_values = [0]*num_policies\n",
        "    cnts = [0]*num_policies\n",
        "    q_plus_cnt = [0]*num_policies\n",
        "    total_count = 0\n",
        "\n",
        "    best_q_values = []\n",
        "\n",
        "    for policy in trange(iterations):\n",
        "\n",
        "        # get the action to try (either initially in order or using best q_plus_cnt value)\n",
        "        if policy >= num_policies:\n",
        "            this_policy = np.argmax(q_plus_cnt)\n",
        "        else:\n",
        "            this_policy = policy\n",
        "\n",
        "        # get info of transformation for this sub-policy\n",
        "        degrees, shear, scale = sample_sub_policy(policies, this_policy, num_sub_policies)\n",
        "\n",
        "        # create transformations using above info\n",
        "        transform = torchvision.transforms.Compose(\n",
        "            [torchvision.transforms.RandomAffine(degrees=(degrees,degrees), shear=(shear,shear), scale=(scale,scale)),\n",
        "            torchvision.transforms.ToTensor()])\n",
        "\n",
        "        # open data and apply these transformations\n",
        "        if ds == \"MNIST\":\n",
        "            train_dataset = datasets.MNIST(root='./MetaAugment/train', train=True, download=True, transform=transform)\n",
        "            test_dataset = datasets.MNIST(root='./MetaAugment/test', train=False, download=True, transform=transform)\n",
        "        elif ds == \"KMNIST\":\n",
        "            train_dataset = datasets.KMNIST(root='./MetaAugment/train', train=True, download=True, transform=transform)\n",
        "            test_dataset = datasets.KMNIST(root='./MetaAugment/test', train=False, download=True, transform=transform)\n",
        "        elif ds == \"FashionMNIST\":\n",
        "            train_dataset = datasets.FashionMNIST(root='./MetaAugment/train', train=True, download=True, transform=transform)\n",
        "            test_dataset = datasets.FashionMNIST(root='./MetaAugment/test', train=False, download=True, transform=transform)\n",
        "        elif ds == \"CIFAR10\":\n",
        "            train_dataset = datasets.CIFAR10(root='./MetaAugment/train', train=True, download=True, transform=transform)\n",
        "            test_dataset = datasets.CIFAR10(root='./MetaAugment/test', train=False, download=True, transform=transform)\n",
        "        elif ds == \"CIFAR100\":\n",
        "            train_dataset = datasets.CIFAR100(root='./MetaAugment/train', train=True, download=True, transform=transform)\n",
        "            test_dataset = datasets.CIFAR100(root='./MetaAugment/test', train=False, download=True, transform=transform)\n",
        "\n",
        "        # check sizes of images\n",
        "        img_height = len(train_dataset[0][0][0])\n",
        "        img_width = len(train_dataset[0][0][0][0])\n",
        "        img_channels = len(train_dataset[0][0])\n",
        "\n",
        "        # check output labels\n",
        "        if ds == \"CIFAR10\" or ds == \"CIFAR100\":\n",
        "            num_labels = (max(train_dataset.targets) - min(train_dataset.targets) + 1)\n",
        "        else:\n",
        "            num_labels = (max(train_dataset.targets) - min(train_dataset.targets) + 1).item()\n",
        "\n",
        "        # create toy dataset from above uploaded data\n",
        "        train_loader, test_loader = create_toy(train_dataset, test_dataset, batch_size, toy_size)\n",
        "\n",
        "        # create model\n",
        "        if IsLeNet == \"LeNet\":\n",
        "            model = LeNet(img_height, img_width, num_labels, img_channels)\n",
        "        elif IsLeNet == \"EasyNet\":\n",
        "            model = EasyNet(img_height, img_width, num_labels, img_channels)\n",
        "        else:\n",
        "            model = SimpleNet(img_height, img_width, num_labels, img_channels)\n",
        "        sgd = optim.SGD(model.parameters(), lr=1e-1)\n",
        "        cost = nn.CrossEntropyLoss()\n",
        "\n",
        "        # set variables for best validation accuracy and early stop count\n",
        "        best_acc = 0\n",
        "        early_stop_cnt = 0\n",
        "\n",
        "        # train model and check validation accuracy each epoch\n",
        "        for _epoch in range(max_epochs):\n",
        "\n",
        "            # train model\n",
        "            model.train()\n",
        "            for idx, (train_x, train_label) in enumerate(train_loader):\n",
        "                label_np = np.zeros((train_label.shape[0], num_labels))\n",
        "                sgd.zero_grad()\n",
        "                predict_y = model(train_x.float())\n",
        "                loss = cost(predict_y, train_label.long())\n",
        "                loss.backward()\n",
        "                sgd.step()\n",
        "\n",
        "            # check validation accuracy on validation set\n",
        "            correct = 0\n",
        "            _sum = 0\n",
        "            model.eval()\n",
        "            for idx, (test_x, test_label) in enumerate(test_loader):\n",
        "                predict_y = model(test_x.float()).detach()\n",
        "                predict_ys = np.argmax(predict_y, axis=-1)\n",
        "                label_np = test_label.numpy()\n",
        "                _ = predict_ys == test_label\n",
        "                correct += np.sum(_.numpy(), axis=-1)\n",
        "                _sum += _.shape[0]\n",
        "            \n",
        "            # update best validation accuracy if it was higher, otherwise increase early stop count\n",
        "            acc = correct / _sum\n",
        "            if acc > best_acc :\n",
        "                best_acc = acc\n",
        "                early_stop_cnt = 0\n",
        "            else:\n",
        "                early_stop_cnt += 1\n",
        "\n",
        "            # exit if validation gets worse over 10 runs\n",
        "            if early_stop_cnt >= early_stop_num:\n",
        "                break\n",
        "\n",
        "        # update q_values\n",
        "        if policy < num_policies:\n",
        "            q_values[this_policy] += best_acc\n",
        "        else:\n",
        "            q_values[this_policy] = (q_values[this_policy]*cnts[this_policy] + best_acc) / (cnts[this_policy] + 1)\n",
        "\n",
        "        best_q_value = max(q_values)\n",
        "        best_q_values.append(best_q_value)\n",
        "\n",
        "        if (policy+1) % 10 == 0:\n",
        "            print(\"Iteration: {},\\tQ-Values: {}, Best Policy: {}\".format(policy+1, list(np.around(np.array(q_values),2)), max(list(np.around(np.array(q_values),2)))))\n",
        "\n",
        "        # update counts\n",
        "        cnts[this_policy] += 1\n",
        "        total_count += 1\n",
        "\n",
        "        # update q_plus_cnt values every turn after the initial sweep through\n",
        "        if policy >= num_policies - 1:\n",
        "            for i in range(num_policies):\n",
        "                q_plus_cnt[i] = q_values[i] + np.sqrt(2*np.log(total_count)/cnts[i])\n",
        "\n",
        "    return q_values, best_q_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "doHUtJ_tEiA6",
        "outputId": "3a7becf3-7b5d-4403-84d3-96e51bac8bf5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 10/100 [01:09<09:26,  6.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 10,\tQ-Values: [0.8, 0.71, 0.79, 0.86, 0.76], Best Policy: 0.86\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 20/100 [02:18<09:03,  6.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 20,\tQ-Values: [0.77, 0.75, 0.81, 0.86, 0.78], Best Policy: 0.86\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 30/100 [03:24<06:50,  5.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 30,\tQ-Values: [0.81, 0.71, 0.79, 0.8, 0.78], Best Policy: 0.81\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 40/100 [04:34<06:14,  6.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 40,\tQ-Values: [0.8, 0.7, 0.76, 0.8, 0.78], Best Policy: 0.8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 50/100 [05:49<06:04,  7.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 50,\tQ-Values: [0.79, 0.72, 0.76, 0.81, 0.74], Best Policy: 0.81\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 60/100 [06:55<04:32,  6.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 60,\tQ-Values: [0.79, 0.72, 0.77, 0.81, 0.76], Best Policy: 0.81\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 70/100 [08:29<04:16,  8.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 70,\tQ-Values: [0.78, 0.7, 0.78, 0.8, 0.76], Best Policy: 0.8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 80/100 [09:38<02:05,  6.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 80,\tQ-Values: [0.79, 0.72, 0.78, 0.79, 0.77], Best Policy: 0.79\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 90/100 [10:41<01:04,  6.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 90,\tQ-Values: [0.79, 0.71, 0.78, 0.79, 0.77], Best Policy: 0.79\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [11:51<00:00,  7.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 100,\tQ-Values: [0.79, 0.72, 0.79, 0.79, 0.78], Best Policy: 0.79\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_size = 32       # size of batch the inner NN is trained with\n",
        "learning_rate = 1e-1  # fix learning rate\n",
        "ds = \"MNIST\"          # pick dataset (MNIST, KMNIST, FashionMNIST, CIFAR10, CIFAR100)\n",
        "toy_size = 0.02       # total propeortion of training and test set we use\n",
        "max_epochs = 100      # max number of epochs that is run if early stopping is not hit\n",
        "early_stop_num = 10   # max number of worse validation scores before early stopping is triggered\n",
        "num_policies = 5      # fix number of policies\n",
        "num_sub_policies = 5  # fix number of sub-policies in a policy\n",
        "iterations = 100      # total iterations, should be more than the number of policies\n",
        "IsLeNet = \"SimpleNet\" # using LeNet or EasyNet or SimpleNet\n",
        "\n",
        "# generate random policies at start\n",
        "policies = generate_policies(num_policies, num_sub_policies)\n",
        "\n",
        "q_values, best_q_values = run_UCB1(policies, batch_size, learning_rate, ds, toy_size, max_epochs, early_stop_num, iterations, IsLeNet)\n",
        "\n",
        "plt.plot(best_q_values)\n",
        "\n",
        "best_q_values = np.array(best_q_values)\n",
        "save('best_q_values_{}_{}percent_{}.npy'.format(IsLeNet, int(toy_size*100), ds), best_q_values)\n",
        "#best_q_values = load('best_q_values_{}_{}percent_{}.npy'.format(IsLeNet, int(toy_size*100), ds), allow_pickle=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "UCB1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
